{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing a custom decision tree\n",
    "source: https://github.com/random-forests/tutorials/blob/master/decision_tree.py\n",
    "\n",
    "Youtube: https://www.youtube.com/watch?v=LDRbO9a6XPU&list=PLOU2XLYxmsIIuiBfYad6rFYQU_jL2ryal&index=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#toy dataset (2d list)\n",
    "#the last column is the label--> fruit\n",
    "#first two columns are features--> color and size\n",
    "training_data = [\n",
    "    ['green', 3, 'apple'],\n",
    "    ['yellow', 3, 'apple'],\n",
    "    ['red', 1, 'grape'],\n",
    "    ['red', 1, 'grape'],\n",
    "    ['yellow', 3, 'lemon']\n",
    "]\n",
    "\n",
    "testing_data = [\n",
    "    ['green', 3, 'apple'],\n",
    "    ['yellow', 4, 'apple'],\n",
    "    ['red', 2, 'grape'],\n",
    "    ['red', 1, 'grape'],\n",
    "    ['yellow', 3, 'lemon']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding column header (only for printing trees, not needed for taining)\n",
    "header = ['color', 'diameter', 'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'green', 'red', 'yellow'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#defining utility function - 1\n",
    "def unique_vals(dataset, col):\n",
    "    #find the unique values for a column in a dataset\n",
    "    return set([row[col] for row in dataset])\n",
    "#example\n",
    "unique_vals(training_data,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'apple': 2, 'grape': 2, 'lemon': 1}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#defining utility function - 2\n",
    "def class_counts(dataset):\n",
    "    #counts the number of each type of example in a dataset\n",
    "    #return the frequency of labels\n",
    "    counts = {} #empty dict of label--> count\n",
    "    for row in dataset:\n",
    "        label = row[-1]\n",
    "        if label not in counts:\n",
    "            counts[label] =0 #creating dict entry for the first time\n",
    "        counts[label]+=1\n",
    "    return counts\n",
    "#example\n",
    "class_counts(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#defining utility function - 3\n",
    "def is_numeric(value):\n",
    "    #test if a value is numeric\n",
    "    return isinstance(value,int) or isinstance(value,float)\n",
    "#example\n",
    "is_numeric(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#defining question class for the decision tree\n",
    "#use to populate set of questions/conditions\n",
    "class Question:\n",
    "    #question is asked to partition the data set in the tree\n",
    "    def __init__(self, column, value):\n",
    "        self.column = column\n",
    "        self.value = value\n",
    "    def match(self, example): #takes training set row\n",
    "        #compare the feature val in the example to that in the question\n",
    "        val = example[self.column]\n",
    "        if is_numeric(val):\n",
    "            return val>=self.value #returns a boolean\n",
    "        else:\n",
    "            return val == self.value #returns a boolean\n",
    "    def __repr__(self):\n",
    "        #helper method to print\n",
    "        #print question in a readable format\n",
    "        condition = \"==\"\n",
    "        if is_numeric(self.value):\n",
    "            condition = \">=\"\n",
    "            return \"Is %s %s %s?\" %(\n",
    "            header[self.column], condition, str(self.value))\n",
    "#example\n",
    "Question(1,3)\n",
    "q = Question(0,'green')\n",
    "q.match(training_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['red', 1, 'grape'], ['red', 1, 'grape']],\n",
       " [['green', 3, 'apple'], ['yellow', 3, 'apple'], ['yellow', 3, 'lemon']])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#defining utility function - 4\n",
    "#partitions a dataset based on the question\n",
    "#For each row in the dataset, check if it matches the question. \n",
    "#If so, add it to 'true rows', otherwise, add it to 'false rows'.\n",
    "\n",
    "def partition(dataset, question):\n",
    "    true_rows, false_rows = [], []\n",
    "    for row in dataset:\n",
    "        if question.match(row):\n",
    "            true_rows.append(row)\n",
    "        else:\n",
    "            false_rows.append(row)\n",
    "    return true_rows, false_rows\n",
    "#demo\n",
    "partition(training_data, Question(0, 'red'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculat the Gini impurity for a list of rows\n",
    "#There are a few different ways to do this, I thought this one was\n",
    "#the most concise. See:\n",
    "#https://en.wikipedia.org/wiki/Decision_tree_learning#Gini_impurity\n",
    "def gini(dataset):\n",
    "    counts = class_counts(dataset)\n",
    "    impurity = 1\n",
    "    for label in counts:\n",
    "        prob_of_label = counts[label]/float(len(dataset))\n",
    "        impurity -= prob_of_label**2\n",
    "    return impurity\n",
    "#demo\n",
    "no_mixing = [['apple'], ['apple']]\n",
    "gini(no_mixing)\n",
    "mixing = [['apple'], ['grape']]\n",
    "gini(mixing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37333333333333324"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "calculate information gain --> The uncertainty of the starting node, minus the weighted impurity of\n",
    "    two child nodes.\n",
    "\"\"\"\n",
    "def info_gain(left, right, current_uncertainty):\n",
    "    p = float(len(left))/ (len(left)+len(right))\n",
    "    return current_uncertainty -p * gini(left) - (1-p)*gini(right)\n",
    "\n",
    "#demo\n",
    "current_uncertainty = gini(training_data)\n",
    "true_rows, false_rows = partition(training_data, Question(0,'red'))\n",
    "info_gain(true_rows, false_rows, current_uncertainty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best gain and question: 0.37333333333333324 , Is diameter >= 3?\n"
     ]
    }
   ],
   "source": [
    "#find the best question to ask by iterating over every feature/value\n",
    "#and calculating information gain\n",
    "def find_best_split(dataset):\n",
    "    best_gain = 0 #keep track of best information gain\n",
    "    best_question = None #keep track of best question to produce best_gain\n",
    "    current_uncertainty = gini(dataset)\n",
    "    n_features = len(dataset[0])-1\n",
    "    for col in range(n_features):\n",
    "        values = set(row[col] for row in dataset) #unique feature values\n",
    "        for val in values:\n",
    "            question = Question(col, val) #create question\n",
    "            #try spliting the data\n",
    "            true_rows, false_rows = partition(dataset, question)\n",
    "            #skip the split if partition cannot be done\n",
    "            if len(true_rows)==0 or len(false_rows) == 0:\n",
    "                continue\n",
    "            #calculate info gain\n",
    "            gain = info_gain(true_rows, false_rows, current_uncertainty)\n",
    "            if gain>=best_gain:\n",
    "                best_gain, best_question = gain, question\n",
    "    return best_gain, best_question\n",
    "\n",
    "#demo\n",
    "best_gain, best_question = find_best_split(training_data)\n",
    "print(f\"Best gain and question: {best_gain} , {best_question}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## defining several aspects before building the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the leaf node classifies data\n",
    "#this holds a dict of class -> number of times it appears in the rows\n",
    "#from the training data that reach this leaf\n",
    "class leaf:\n",
    "    def __init__(self, dataset):\n",
    "        self.predictions = class_counts(dataset)\n",
    "#A decision node -> Holds the reference to a question and to the\n",
    "#two child nodes\n",
    "class Decision_Node:\n",
    "    def __init__(self,\n",
    "                question,\n",
    "                true_branch,\n",
    "                false_branch):\n",
    "        self.question = question\n",
    "        self.true_branch = true_branch\n",
    "        self.false_branch = false_branch\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build the tree\n",
    "#build the recursion. base case -> no further information gain\n",
    "def build_tree(dataset):\n",
    "    best_gain, best_question = find_best_split(dataset)\n",
    "    #base case definition\n",
    "    if best_gain == 0:\n",
    "        return leaf(dataset)\n",
    "    true_rows, false_rows = partition(dataset, best_question)\n",
    "    #build recursion\n",
    "    true_branch = build_tree(true_rows)\n",
    "    false_branch = build_tree(false_rows)\n",
    "    return Decision_Node(best_question, true_branch, false_branch) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#printing tree\n",
    "def print_tree(node, spacing =\"\"):\n",
    "    #base case: in case we have a leaf\n",
    "    if isinstance(node, leaf):\n",
    "        print(spacing+\"Predict\", node.predictions)\n",
    "        return\n",
    "    print (spacing+str(node.question))\n",
    "    #call this function recursively over the branches\n",
    "    print(spacing+'--> True:')\n",
    "    print_tree(node.true_branch, spacing+\" \")\n",
    "    print_tree(node.false_branch, spacing+\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write a classifer: trained by build_tree\n",
    "def classify(row, node):\n",
    "    #base case: in case leaf node \n",
    "    if isinstance(node, leaf):\n",
    "        return node.predictions\n",
    "    #decide whether to follow true/false brance\n",
    "    if node.question.match(row):\n",
    "        return classify(row, node.true_branch)\n",
    "    else:\n",
    "        return classify(row, node.false_branch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'apple': 1}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tree = build_tree(training_data)\n",
    "classify(training_data[0], my_tree)\n",
    "#print_tree(my_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
